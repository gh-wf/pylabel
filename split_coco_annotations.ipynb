{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f8f571d",
   "metadata": {},
   "source": [
    "# Load the JSON File With all of the Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ef33d75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['images', 'annotations', 'categories'])\n",
      "29620\n",
      "116153\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "orig_file = '/home/datascience/epri_drone_dist_renamed.json'\n",
    "\n",
    "with open(orig_file, 'r') as jf:\n",
    "    jsonFile = json.load(jf)\n",
    "    \n",
    "print(jsonFile.keys())\n",
    "print(len(jsonFile['images']))\n",
    "print(len(jsonFile['annotations']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42589ace",
   "metadata": {},
   "source": [
    "The goal is to first remove images from the images dict that do not exist in the specified image folder.\n",
    "Secondly we will remove the annotations that do not have a matching image_id in the images dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f0d5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12333\n",
      "116153\n",
      "{'image_id': 0, 'id': 0, 'segmented': None, 'bbox': [290, 426, 71, 100], 'area': 118030.0, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 3, 'difficult': None}\n",
      "{'image_id': 0, 'id': 1, 'segmented': None, 'bbox': [608, 282, 69, 165], 'area': 190176.0, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 3, 'difficult': None}\n",
      "{'image_id': 0, 'id': 2, 'segmented': None, 'bbox': [928, 336, 64, 100], 'area': 106080.0, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 3, 'difficult': None}\n",
      "{'image_id': 0, 'id': 3, 'segmented': None, 'bbox': [877, 676, 132, 54], 'area': 119436.0, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 3, 'difficult': None}\n",
      "{'image_id': 0, 'id': 4, 'segmented': None, 'bbox': [279, 395, 730, 157], 'area': 1885520.0, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 1, 'difficult': None}\n",
      "{'image_id': 0, 'id': 5, 'segmented': None, 'bbox': [601, 375, 110, 584], 'area': 1056573.9999999998, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 4, 'difficult': None}\n",
      "{'image_id': 0, 'id': 6, 'segmented': None, 'bbox': [340, 360, 66, 136], 'area': 149580.0, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 2, 'difficult': None}\n",
      "{'image_id': 0, 'id': 7, 'segmented': None, 'bbox': [828, 299, 80, 132], 'area': 174410.0, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 2, 'difficult': None}\n",
      "{'image_id': 0, 'id': 8, 'segmented': None, 'bbox': [279, 718, 335, 241], 'area': 1330080.0, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 5, 'difficult': None}\n",
      "{'image_id': 1, 'id': 9, 'segmented': None, 'bbox': [526, 0, 284, 958], 'area': 4467031.0, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 4, 'difficult': None}\n",
      "{'image_id': 2, 'id': 10, 'segmented': None, 'bbox': [325, 419, 62, 98], 'area': 101346.0, 'segmentation': None, 'iscrowd': 0.0, 'pose': None, 'truncated': None, 'category_id': 3, 'difficult': None}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "\n",
    "#image_folder = '/home/datascience/test1280/images'\n",
    "image_folders = ['/home/datascience/train1280/images', '/home/datascience/test1280/images']\n",
    "train_test = ['train', 'test']\n",
    "\n",
    "\n",
    "for test_or_train in train_test:\n",
    "    \n",
    "    image_folder = f'/home/datascience/{test_or_train}1280/images'\n",
    "    img_list = os.listdir(image_folder)\n",
    "    expected = [item for item in jsonFile['images'] if item['file_name'] in img_list]\n",
    "    jsonFile['images'] = expected\n",
    "\n",
    "    print(len(jsonFile['images']))\n",
    "    print(len(jsonFile['annotations']))\n",
    "    \n",
    "    id_list = [item['id'] for item in expected]\n",
    "    \n",
    "    expected_annotations = [item for item in jsonFile['annotations'] if item['image_id'] in id_list]\n",
    "    \n",
    "    scale = 4.05\n",
    "    for anno in expected_annotations:\n",
    "        anno['bbox'] = [int(val/scale) for val in anno['bbox']] #original annotations based on 5184px width and new images are 1280px width\n",
    "        print(anno)\n",
    "        sleep(1)\n",
    "    print(len(expected_annotations))\n",
    "    \n",
    "    jsonFile['annotations'] = expected_annotations\n",
    "    \n",
    "    new_file = f'/home/datascience/{test_or_train}1280/images/annotations.json'\n",
    "\n",
    "    json_object = json.dumps(jsonFile, indent=4)\n",
    "\n",
    "#     with open(new_file, \"w\") as outfile:\n",
    "#         outfile.write(json_object)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec8ef68",
   "metadata": {},
   "source": [
    "# Consider scaling the annotations here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c583bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = '/home/datascience/train1280/images/annotations.json'\n",
    "with open(in_file, 'r') as jf:\n",
    "    jsonFile = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "96bd6bb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjsonFile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mannotations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbbox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4.05\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "jsonFile['annotations'][0]['bbox'] / 4.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd5046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
